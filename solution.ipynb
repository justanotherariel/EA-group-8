{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving a Lunar Lander with differentiable Genetic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from genepro.node_impl import *\n",
    "from genepro.evo import Evolution\n",
    "from genepro.node_impl import Constant\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "device = torch.device(dev)  \n",
    "print(device)\n",
    "a = torch.zeros(4,3)    \n",
    "a = a.to(device)\n",
    "# print(torch.cuda.set_device(1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycuda in c:\\users\\wk\\anaconda3\\envs\\genepro23\\lib\\site-packages (2022.2.2)\n",
      "Requirement already satisfied: pytools>=2011.2 in c:\\users\\wk\\anaconda3\\envs\\genepro23\\lib\\site-packages (from pycuda) (2022.1.14)\n",
      "Requirement already satisfied: appdirs>=1.4.0 in c:\\users\\wk\\anaconda3\\envs\\genepro23\\lib\\site-packages (from pycuda) (1.4.4)\n",
      "Requirement already satisfied: mako in c:\\users\\wk\\anaconda3\\envs\\genepro23\\lib\\site-packages (from pycuda) (1.2.4)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in c:\\users\\wk\\anaconda3\\envs\\genepro23\\lib\\site-packages (from pytools>=2011.2->pycuda) (3.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in c:\\users\\wk\\anaconda3\\envs\\genepro23\\lib\\site-packages (from pytools>=2011.2->pycuda) (4.6.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\wk\\anaconda3\\envs\\genepro23\\lib\\site-packages (from mako->pycuda) (2.1.3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Quadro P1000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install pycuda\n",
    "import torch\n",
    "import pycuda.driver as cuda\n",
    "cuda.init()\n",
    "## Get Id of default device\n",
    "torch.cuda.current_device()\n",
    "# 0\n",
    "cuda.Device(0).name() # '0' is the id of your GPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sets it to first one, aka intel hd stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # Use GPU 0\n",
    "else:\n",
    "    device = torch.device(\"cpu\")     # Use CPU\n",
    "\n",
    "# Set the device for tensors\n",
    "torch.cuda.set_device(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda.Device(0).name()\n",
    "# torch.Device(0).name()\n",
    "# torch.device(\"cuda:0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set it to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Check if CUDA is available\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(torch.cuda.get_device_name(0))  # Use GPU 0\n",
    "#     # device = torch.device(cuda.Device(0))\n",
    "    \n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")  # Use CPU\n",
    "\n",
    "# # Set the device for tensors\n",
    "# torch.cuda.set_device(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device_index = 0  # Replace with the index of your GPU\n",
    "    device = torch.device('cuda:' + str(device_index) if torch.cuda.is_available() else 'cpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Set the device for tensors\n",
    "torch.cuda.set_device(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: Quadro P1000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check the current device\n",
    "device = torch.cuda.current_device()\n",
    "print(\"Current device:\", torch.cuda.get_device_name(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "      self.memory += other.memory\n",
    "      return self \n",
    "\n",
    "    def __add__(self, other):\n",
    "      self.memory = self.memory + other.memory \n",
    "      return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function_pt(multitree, num_episodes=5, episode_duration=300, render=False, ignore_done=False):\n",
    "  memory = ReplayMemory(10000)\n",
    "  rewards = []\n",
    "\n",
    "  for _ in range(num_episodes):\n",
    "    # get initial state of the environment\n",
    "    observation = env.reset()\n",
    "    observation = observation[0]\n",
    "    \n",
    "    for _ in range(episode_duration):\n",
    "      if render:\n",
    "        frames.append(env.render())\n",
    "\n",
    "      input_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "      \n",
    "      # what goes here? TODO\n",
    "      action = torch.argmax(multitree.get_output_pt(input_sample))\n",
    "      observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "      rewards.append(reward)\n",
    "      output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "      memory.push(input_sample, torch.tensor([[action.item()]]), output_sample, torch.tensor([reward]))\n",
    "      if (terminated or truncated) and not ignore_done:\n",
    "        break\n",
    "\n",
    "  fitness = np.sum(rewards)\n",
    "  \n",
    "  return fitness, memory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution Setup\n",
    "Here the leaf and internal nodes are defined. Think about the odds of sampling a constant in this default configurations. Also think about any operators that could be useful and add them here. \n",
    "\n",
    "Adjust the population size (multiple of 8 if you want to use the standard tournament selection), max generations and max tree size to taste. Be aware that each of these settings can increase the runtime."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base attempt 1, different nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen: 1,\tbest of gen fitness: -525.334,\tbest of gen size: 19\n",
      "gen: 2,\tbest of gen fitness: -390.195,\tbest of gen size: 19\n",
      "gen: 3,\tbest of gen fitness: -369.751,\tbest of gen size: 19\n",
      "gen: 4,\tbest of gen fitness: -331.039,\tbest of gen size: 32\n",
      "gen: 5,\tbest of gen fitness: -315.249,\tbest of gen size: 19\n",
      "gen: 6,\tbest of gen fitness: -260.795,\tbest of gen size: 32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 26\u001b[0m\n\u001b[0;32m      9\u001b[0m base_evo \u001b[39m=\u001b[39m Evolution(\n\u001b[0;32m     10\u001b[0m     fitness_function_pt, internal_nodes_base, leaf_nodes_base, \u001b[39m4\u001b[39m,\n\u001b[0;32m     11\u001b[0m     pop_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[39m# selection = 8,\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     )\n\u001b[0;32m     25\u001b[0m \u001b[39m# Run the evolution\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m base_evo\u001b[39m.\u001b[39;49mevolve()\n",
      "File \u001b[1;32mc:\\Users\\WK\\Documents\\GitHub\\CS4205_g8\\Reboot\\genepromulti-main\\genepromulti-main\\genepro\\evo.py:240\u001b[0m, in \u001b[0;36mEvolution.evolve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m# generational loop\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_must_terminate():\n\u001b[0;32m    239\u001b[0m   \u001b[39m# perform one generation\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_perform_generation()\n\u001b[0;32m    241\u001b[0m   \u001b[39m# log info\u001b[39;00m\n\u001b[0;32m    242\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[1;32mc:\\Users\\WK\\Documents\\GitHub\\CS4205_g8\\Reboot\\genepromulti-main\\genepromulti-main\\genepro\\evo.py:203\u001b[0m, in \u001b[0;36mEvolution._perform_generation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    196\u001b[0m offspring_population \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)(delayed(generate_offspring)\n\u001b[0;32m    197\u001b[0m   (t, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrossovers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmutations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoeff_opts, \n\u001b[0;32m    198\u001b[0m   parents, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minternal_nodes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleaf_nodes,\n\u001b[0;32m    199\u001b[0m   constraints\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmax_tree_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_tree_size}) \n\u001b[0;32m    200\u001b[0m   \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m parents)\n\u001b[0;32m    202\u001b[0m \u001b[39m# evaluate each offspring and store its fitness \u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m fitnesses \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(delayed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitness_function)(t) \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m offspring_population)\n\u001b[0;32m    204\u001b[0m fitnesses \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlist\u001b[39m, \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfitnesses)))\n\u001b[0;32m    205\u001b[0m memories \u001b[39m=\u001b[39m fitnesses[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\WK\\Anaconda3\\envs\\genepro23\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\WK\\Anaconda3\\envs\\genepro23\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\WK\\Anaconda3\\envs\\genepro23\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\WK\\Anaconda3\\envs\\genepro23\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\WK\\Anaconda3\\envs\\genepro23\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes = leaf_nodes + [Constant()] # Think about the probability of sampling a coefficient\n",
    "# Atomic funtions for the baseline solution\n",
    "internal_nodes_base = [Plus(),Minus(),Times(),Div(),Log(),Abs()]\n",
    "leaf_nodes_base = leaf_nodes # as defined at the beginning\n",
    "\n",
    "# Create evolution object\n",
    "base_evo = Evolution(\n",
    "    fitness_function_pt, internal_nodes_base, leaf_nodes_base, 4,\n",
    "    pop_size=64, \n",
    "    # max_gens=70, \n",
    "    max_gens=20,\n",
    "    max_tree_size=32, \n",
    "    n_jobs=6, verbose=True,\n",
    "    init_max_depth = 4,\n",
    "    # max_tree_size : int=64,\n",
    "    # crossover = [{\"fun\":subtree_crossover, \"rate\": 0.5}],\n",
    "    # crossovers = 0.4,\n",
    "    # mutations = 0.5,\n",
    "    # coeff_opts = 0.5,\n",
    "    # selection = 8,\n",
    "    )\n",
    "\n",
    "# Run the evolution\n",
    "base_evo.evolve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "redo with more gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes = leaf_nodes + [Constant()] # Think about the probability of sampling a coefficient\n",
    "# Atomic funtions for the baseline solution\n",
    "internal_nodes_base = [Plus(),Minus(),Times(),Div(),Log(),Abs()]\n",
    "leaf_nodes_base = leaf_nodes # as defined at the beginning\n",
    "\n",
    "# Create evolution object\n",
    "base_evo = Evolution(\n",
    "    fitness_function_pt, internal_nodes_base, leaf_nodes_base, 4,\n",
    "    pop_size=64, \n",
    "    # max_gens=70, \n",
    "    max_gens=70,\n",
    "    max_tree_size=32, \n",
    "    n_jobs=6, verbose=True,\n",
    "    init_max_depth = 4,\n",
    "    # max_tree_size : int=64,\n",
    "    # crossover = [{\"fun\":subtree_crossover, \"rate\": 0.5}],\n",
    "    # crossovers = 0.4,\n",
    "    # mutations = 0.5,\n",
    "    # coeff_opts = 0.5,\n",
    "    # selection = 8,\n",
    "    )\n",
    "\n",
    "# Run the evolution\n",
    "base_evo.evolve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base attempt 2, added log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes = leaf_nodes + [Constant()] # Think about the probability of sampling a coefficient\n",
    "internal_nodes = [Plus(),Minus(),Times(),Div(), Log()] #Add your own operators here\n",
    "\n",
    "evo = Evolution(\n",
    "  fitness_function_pt, internal_nodes, leaf_nodes,\n",
    "  4, # default is 4, number of trees in multitree\n",
    "  pop_size=64,\n",
    "  max_gens=20,\n",
    "  max_tree_size=31,\n",
    "  n_jobs=6,\n",
    "  verbose=True)\n",
    "evo.evolve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU attempt up population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes = leaf_nodes + [Constant()] # Think about the probability of sampling a coefficient\n",
    "internal_nodes = [Plus(),Minus(),Times(),Div(), Log()] #Add your own operators here\n",
    "\n",
    "evo = Evolution(\n",
    "  fitness_function_pt, internal_nodes, leaf_nodes,\n",
    "  4, # default is 4, number of trees in multitree\n",
    "  pop_size=1024,\n",
    "  max_gens=3,\n",
    "  max_tree_size=64,\n",
    "  n_jobs=6,\n",
    "  verbose=True)\n",
    "evo.evolve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline higher population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atomic funtions for the baseline solution\n",
    "internal_nodes_base = [Plus(),Minus(),Times(),Div(),Log()]\n",
    "leaf_nodes_base = leaf_nodes # as defined at the beginning\n",
    "\n",
    "# Create evolution object\n",
    "base_evo = Evolution(\n",
    "    fitness_function_pt, internal_nodes_base, leaf_nodes_base, 4,\n",
    "    pop_size=200, \n",
    "    # max_gens=70, \n",
    "    max_gens=20,\n",
    "    max_tree_size=64, \n",
    "    n_jobs=6, verbose=True,\n",
    "    init_max_depth = 4,\n",
    "    # max_tree_size : int=64,\n",
    "    # crossover = [{\"fun\":subtree_crossover, \"rate\": 0.5}],\n",
    "    # crossovers = 0.4,\n",
    "    # mutations = 0.5,\n",
    "    # coeff_opts = 0.5,\n",
    "    # selection = 8,\n",
    "    )\n",
    "\n",
    "# Run the evolution\n",
    "base_evo.evolve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline with ifThenElse, final from 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better set of atomic funtions for this problem\n",
    "internal_nodes_final = [Plus(),Minus(),Times(),IfThenElse()]\n",
    "leaf_nodes_final = leaf_nodes_base # do no use the previous actions\n",
    "\n",
    "# Create evolution object\n",
    "final_evo = Evolution(\n",
    "    lander_fitness_function_complete, internal_nodes_final, leaf_nodes_final,4, # Use adapted fitness function that performs mirroring\n",
    "    pop_size=200, max_gens=70, max_tree_size=64, n_jobs=6, verbose=True,\n",
    "    mutations  = [{\"fun\":subtree_mutation, \"rate\": 0.7}],\n",
    "    crossovers = [{\"fun\":sided_subtree_crossover, \"rate\": 0.4}],  # Use the adapted crossover function\n",
    "    # mutations  = [{\"fun\":subtree_mutation, \"rate\": 0.3}],\n",
    "    # crossovers = [{\"fun\":sided_subtree_crossover, \"rate\": 0.5}],  # Use the adapted crossover function\n",
    "    # selection  = [{\"fun\":tournament_selection, \"tournament_size\":4}])\n",
    "    selection={\"fun\":tournament_selection,\"kwargs\":{\"tournament_size\":4}})\n",
    "# Run the evolution\n",
    "final_evo.evolve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evolution object\n",
    "default_evo = Evolution(\n",
    "     fitness_function_pt, internal_nodes_base, leaf_nodes_base, 4,\n",
    "    pop_size=256, \n",
    "    init_max_depth=4,\n",
    "    max_tree_size=64,\n",
    "    # crossovers : list=[{\"fun\":subtree_crossover, \"rate\": 0.5}],\n",
    "    # mutations : list= [{\"fun\":subtree_mutation, \"rate\": 0.5}],\n",
    "    # coeff_opts : list = [{\"fun\":coeff_mutation, \"rate\": 0.5}],\n",
    "    # selection : dict={\"fun\":tournament_selection,\"kwargs\":{\"tournament_size\":8}},\n",
    "    # termination criteria\n",
    "    # max_evals : int=None,\n",
    "    # max_gens : int=100,\n",
    "    # max_time : int=None,\n",
    "    # other\n",
    "    # n_jobs : int=4,\n",
    "    # verbose : bool=False,\n",
    "    )\n",
    "# Run the evolution\n",
    "default_evo.evolve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolve\n",
    "Running this cell will use all the settings above as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo.evolve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_score(tree):\n",
    "    rewards = []\n",
    "\n",
    "    for i in range(10):\n",
    "      # get initial state\n",
    "      observation = env.reset(seed=i)\n",
    "      observation = observation[0]\n",
    "\n",
    "      for _ in range(500):    \n",
    "        # build up the input sample for GP\n",
    "        input_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        # get output (squeezing because it is encapsulated in an array)\n",
    "        output = tree.get_output_pt(input_sample)\n",
    "        action = action = torch.Tensor.argmax(output)# What goes here?\n",
    "        observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "        rewards.append(reward)\n",
    "\n",
    "\n",
    "        output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        if (terminated or truncated):\n",
    "            break\n",
    "\n",
    "    fitness = np.sum(rewards)\n",
    "    \n",
    "    return fitness\n",
    "\n",
    "best = evo.best_of_gens[-1]\n",
    "\n",
    "print(best.get_readable_repr())\n",
    "print(get_test_score(best))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an animation\n",
    "Here the best evolved individual is selected and one episode is rendered. Make sure to save your lunar landers over time to track progress and make comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "# gist to save gif from https://gist.github.com/botforge/64cbb71780e6208172bbf03cd9293553\n",
    "def save_frames_as_gif(frames, path='./', filename='evolved_lander.gif'):\n",
    "  plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "  patch = plt.imshow(frames[0])\n",
    "  plt.axis('off')\n",
    "  def animate(i):\n",
    "      patch.set_data(frames[i])\n",
    "  anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "  anim.save(path + filename, writer='imagemagick', fps=60)\n",
    "\n",
    "frames = []\n",
    "fitness_function_pt(best, num_episodes=1, episode_duration=500, render=True, ignore_done=False)\n",
    "env.close()\n",
    "save_frames_as_gif(frames)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play animation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander.gif\" width=\"750\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "The coefficients in the multi-tree aren't optimised. Here Q-learning (taken from https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html) is used to optimise the weights further. Incorporate coefficient optimisation in training your agent(s). Coefficient Optimisation can be expensive. Think about how often you want to optimise, when, which individuals etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "GAMMA = 0.99\n",
    "\n",
    "constants = best.get_subtrees_consts()\n",
    "\n",
    "if len(constants)>0:\n",
    "  optimizer = optim.AdamW(constants, lr=1e-3, amsgrad=True)\n",
    "\n",
    "for _ in range(500):\n",
    "\n",
    "  if len(constants)>0 and len(evo.memory)>batch_size:\n",
    "    target_tree = copy.deepcopy(best)\n",
    "\n",
    "    transitions = evo.memory.sample(batch_size)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                        batch.next_state)), dtype=torch.bool)\n",
    "\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                               if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = best.get_output_pt(state_batch).gather(1, action_batch)\n",
    "    next_state_values = torch.zeros(batch_size, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "      next_state_values[non_final_mask] = target_tree.get_output_pt(non_final_next_states).max(1)[0].float()\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    \n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "   \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(constants, 100)\n",
    "    optimizer.step()\n",
    "\n",
    "print(best.get_readable_repr())\n",
    "print(get_test_score(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "fitness_function_pt(best, num_episodes=1, episode_duration=500, render=True, ignore_done=False)\n",
    "env.close()\n",
    "save_frames_as_gif(frames, filename='evolved_lander_RL.gif')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander_RL.gif\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genepro23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
