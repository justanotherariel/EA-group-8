{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving a Lunar Lander with differentiable Genetic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "To install the required libraries run the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-display\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Imports from the standard genepro-multi library are done here. Any adjustments (e.g. different operators) should be made in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from genepro.node_impl import *\n",
    "from genepro.evo import Evolution\n",
    "from genepro.node_impl import Constant\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Setup\n",
    "Here we first setup the Gymnasium environment. Please see https://gymnasium.farama.org/environments/box2d/lunar_lander/ for more information on the environment. \n",
    "\n",
    "Then a memory buffer is made. This is a buffer in which state transitions are stored. When the buffer reaches its maximum capacity old transitions are replaced by new ones.\n",
    "\n",
    "A frame buffer is initialised used to later store animation frames of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "      self.memory += other.memory\n",
    "      return self \n",
    "\n",
    "    def __add__(self, other):\n",
    "      self.memory = self.memory + other.memory \n",
    "      return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Function\n",
    "\n",
    "Here you get to be creative. The default setup evaluates 5 episodes of 300 frames. Think of what action to pick and what fitness function to use. The Multi-tree takes an input of $n \\times d$ where $n$ is a batch of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function_pt(multitree, generation, num_episodes=5, episode_duration=300, render=False, ignore_done=False):\n",
    "  memory = ReplayMemory(10000)\n",
    "  rewards = []\n",
    "\n",
    "  for i in range(num_episodes):\n",
    "    # get initial state of the environment\n",
    "    observation = env.reset(seed=(generation*1000 + i))\n",
    "    observation = observation[0]\n",
    "    \n",
    "    for _ in range(episode_duration):\n",
    "      if render:\n",
    "        frames.append(env.render())\n",
    "\n",
    "      input_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "      \n",
    "      action = torch.argmax(multitree.get_output_pt(input_sample))\n",
    "      observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "      rewards.append(reward)\n",
    "      output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "      memory.push(input_sample, torch.tensor([[action.item()]]), output_sample, torch.tensor([reward]))\n",
    "      if (terminated or truncated) and not ignore_done:\n",
    "        break\n",
    "\n",
    "  fitness = np.sum(rewards)/num_episodes\n",
    "  return fitness, memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution Setup & Evolve\n",
    "Here the leaf and internal nodes are defined. Think about the odds of sampling a constant in this default configurations. Also think about any operators that could be useful and add them here. \n",
    "\n",
    "Adjust the population size (multiple of 8 if you want to use the standard tournament selection), max generations and max tree size to taste. Be aware that each of these settings can increase the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 1\n",
      "\tBest - \tFitness: -130.099, Size: 13\n",
      "\tPopulation - \tAverage Fitness: -229.2248766566567\n",
      "\tmean = -229.22, \tmedian = -186.60, \tbest_median = -186.60\n",
      "\n",
      "Last Generation - Thorough Eval\n",
      "Generation: 2\n",
      "\tBest - \tFitness: -129.977, Size: 13\n",
      "\tPopulation - \tAverage Fitness: -136.51681924959553\n",
      "\tmean = -136.52, \tmedian = -137.59, \tbest_median = -137.59\n",
      "\n",
      "Generation: 1\n",
      "\tBest - \tFitness: -106.572, Size: 24\n",
      "\tPopulation - \tAverage Fitness: -126.21699992209501\n",
      "\tmean = -126.22, \tmedian = -129.02, \tbest_median = -129.02\n",
      "\n",
      "Last Generation - Thorough Eval\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      9\u001b[0m   evo \u001b[38;5;241m=\u001b[39m Evolution(\n\u001b[1;32m     10\u001b[0m     fitness_function_pt, internal_nodes, leaf_nodes,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     log_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m   \u001b[43mevo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/genepro/evo.py:271\u001b[0m, in \u001b[0;36mEvolution.evolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/genepro/evo.py?line=268'>269</a>\u001b[0m \u001b[39m# Generational Loop\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/genepro/evo.py?line=269'>270</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_must_terminate():\n\u001b[0;32m--> <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/genepro/evo.py?line=270'>271</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_perform_generation()\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/genepro/evo.py?line=272'>273</a>\u001b[0m   \u001b[39m# Save Statistics of current gen\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/genepro/evo.py?line=273'>274</a>\u001b[0m   stats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatistics[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_gens \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]  \u001b[39m# Gens start at 1\u001b[39;00m\n",
      "File \u001b[0;32m~/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/genepro/evo.py:213\u001b[0m, in \u001b[0;36mEvolution._perform_generation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/genepro/evo.py?line=210'>211</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_gens \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_gens \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/genepro/evo.py?line=211'>212</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLast Generation - Thorough Eval\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/genepro/evo.py?line=212'>213</a>\u001b[0m   fit_out \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(delayed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitness_function)(t, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_gens, num_episodes\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m offspring_population)\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/genepro/evo.py?line=213'>214</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/genepro/evo.py?line=214'>215</a>\u001b[0m   fit_out \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)(delayed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness_function)(t, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_gens) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m offspring_population)\n",
      "File \u001b[0;32m~/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/parallel.py?line=1094'>1095</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/parallel.py?line=1096'>1097</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/parallel.py?line=1097'>1098</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/parallel.py?line=1098'>1099</a>\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/parallel.py?line=1099'>1100</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/parallel.py?line=972'>973</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/parallel.py?line=973'>974</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/parallel.py?line=974'>975</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/parallel.py?line=975'>976</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/parallel.py?line=976'>977</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=563'>564</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=564'>565</a>\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=565'>566</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=566'>567</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=567'>568</a>\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///home/ariel/University/master/4th-quarter_2023S/evolutionary-algorithms/project-impr-1/env/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.9/concurrent/futures/_base.py?line=437'>438</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    <a href='file:///usr/lib/python3.9/concurrent/futures/_base.py?line=438'>439</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> <a href='file:///usr/lib/python3.9/concurrent/futures/_base.py?line=440'>441</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    <a href='file:///usr/lib/python3.9/concurrent/futures/_base.py?line=442'>443</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    <a href='file:///usr/lib/python3.9/concurrent/futures/_base.py?line=443'>444</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.9/threading.py?line=309'>310</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3.9/threading.py?line=310'>311</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/lib/python3.9/threading.py?line=311'>312</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    <a href='file:///usr/lib/python3.9/threading.py?line=312'>313</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3.9/threading.py?line=313'>314</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)] + [Constant() for _ in range(1)]\n",
    "internal_nodes = [Plus(), Minus(), Times(), Div(), Square(), Sqrt(), Log(), Sin(), Cos(), Max(), Min()] #Add your own operators here\n",
    "\n",
    "# Run a few times to collect Data\n",
    "for _ in range(5):\n",
    "  evo = Evolution(\n",
    "    fitness_function_pt, internal_nodes, leaf_nodes,\n",
    "    4,\n",
    "    pop_size=8,\n",
    "    max_gens=2,\n",
    "    max_tree_size=31,\n",
    "    n_jobs=8,\n",
    "    log_data=True,\n",
    "    verbose=True)\n",
    "  \n",
    "  evo.evolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sqrt(abs(((min(sin((max(sqrt(abs((x_5/((x_1)**2*(cos(log(abs(x_5)))*(max(x_0,x_1)-sin(max(x_6,x_4)))))))),sin(x_6)))**2),-1.3413521770946741)*sin(x_1)))**2))', '(log(abs(cos(min(((x_1+x_3)*min(log(abs(x_6)),cos(min(x_0,x_0)))),max((x_0/((x_1+x_3)*min(log(abs(x_6)),cos(min(x_0,x_0))))),x_2)))))/x_3)', '(x_3)**2', '(log(abs(x_1))+max(((x_1+x_1)/x_5),cos(min(log(abs((sin((max(max(x_7,x_0),x_3)/(x_1/cos(x_6)))))**2)),-4.096794435806871))))']\n",
      "0.1485058382296766\n"
     ]
    }
   ],
   "source": [
    "def get_test_score(tree):\n",
    "    rewards = []\n",
    "\n",
    "    for i in range(10):\n",
    "      # get initial state\n",
    "      observation = env.reset(seed=i)\n",
    "      observation = observation[0]\n",
    "\n",
    "      for _ in range(500):    \n",
    "        # build up the input sample for GP\n",
    "        input_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        # get output (squeezing because it is encapsulated in an array)\n",
    "        output = tree.get_output_pt(input_sample)\n",
    "        action = torch.argmax(output)\n",
    "        observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "        rewards.append(reward)\n",
    "\n",
    "        output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        if (terminated or truncated):\n",
    "            break\n",
    "\n",
    "    fitness = np.mean(rewards)\n",
    "    \n",
    "    return fitness\n",
    "\n",
    "best = evo.best_of_gens[-1]\n",
    "\n",
    "print(best.get_readable_repr())\n",
    "print(get_test_score(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an animation\n",
    "Here the best evolved individual is selected and one episode is rendered. Make sure to save your lunar landers over time to track progress and make comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = evo.best_of_gens[-1]\n",
    "\n",
    "frames = []\n",
    "\n",
    "# gist to save gif from https://gist.github.com/botforge/64cbb71780e6208172bbf03cd9293553\n",
    "def save_frames_as_gif(frames, path='./', filename='evolved_lander.gif'):\n",
    "  plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "  patch = plt.imshow(frames[0])\n",
    "  plt.axis('off')\n",
    "  def animate(i):\n",
    "      patch.set_data(frames[i])\n",
    "  anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "  anim.save(path + filename, writer='imagemagick', fps=60)\n",
    "\n",
    "frames = []\n",
    "fitness_function_pt(best, generation = 0, num_episodes=1, episode_duration=500, render=True, ignore_done=False)\n",
    "env.close()\n",
    "save_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander.gif\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "The coefficients in the multi-tree aren't optimised. Here Q-learning (taken from https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html) is used to optimise the weights further. Incorporate coefficient optimisation in training your agent(s). Coefficient Optimisation can be expensive. Think about how often you want to optimise, when, which individuals etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "GAMMA = 0.99\n",
    "\n",
    "constants = best.get_subtrees_consts()\n",
    "\n",
    "if len(constants)>0:\n",
    "  optimizer = optim.AdamW(constants, lr=1e-3, amsgrad=True)\n",
    "\n",
    "for _ in range(500):\n",
    "\n",
    "  if len(constants)>0 and len(evo.memory)>batch_size:\n",
    "    target_tree = copy.deepcopy(best)\n",
    "\n",
    "    transitions = evo.memory.sample(batch_size)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                        batch.next_state)), dtype=torch.bool)\n",
    "\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                               if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = best.get_output_pt(state_batch).gather(1, action_batch)\n",
    "    next_state_values = torch.zeros(batch_size, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "      next_state_values[non_final_mask] = target_tree.get_output_pt(non_final_next_states).max(1)[0].float()\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    \n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "   \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(constants, 100)\n",
    "    optimizer.step()\n",
    "\n",
    "print(best.get_readable_repr())\n",
    "print(get_test_score(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "fitness_function_pt(best, num_episodes=1, episode_duration=500, render=True, ignore_done=False)\n",
    "env.close()\n",
    "save_frames_as_gif(frames, filename='evolved_lander_RL.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander_RL.gif\" width=\"750\">"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "418dcdb4d37babd9dbe9edab2c2ef3757f3166f0f7f6579e9d679af19abe9b1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
